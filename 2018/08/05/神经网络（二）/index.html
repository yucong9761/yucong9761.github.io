<!DOCTYPE html>
<html >
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="聪聪&amp;&amp;蝶蝶" />



<meta name="description" content="神经网络基础二分分类（logistic回归）计算机保存照片：建立保存三个独立的矩阵，分别对应图片中的红、绿、蓝三个颜色通道（eg：输入图片是64×64像素，则有三个64×64的矩阵）。把这些像素亮度值放进一个特征向量中，就要把这些像素值提出来，放入一个特征向量x，把所有像素值取出来（红、绿、蓝像素强度值都列出来）放入x">
<meta name="keywords" content="神经网络">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络（二）">
<meta property="og:url" content="http://yoursite.com/2018/08/05/神经网络（二）/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="神经网络基础二分分类（logistic回归）计算机保存照片：建立保存三个独立的矩阵，分别对应图片中的红、绿、蓝三个颜色通道（eg：输入图片是64×64像素，则有三个64×64的矩阵）。把这些像素亮度值放进一个特征向量中，就要把这些像素值提出来，放入一个特征向量x，把所有像素值取出来（红、绿、蓝像素强度值都列出来）放入x（1列 64×64×3行）。二分分类：以图片特征向量x作为输入，预测输出的结果标">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/1.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/2.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/3.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/4.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/5.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/6.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/7.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/8.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/9.PNG">
<meta property="og:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/10.PNG">
<meta property="og:updated_time" content="2018-08-09T03:17:15.600Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神经网络（二）">
<meta name="twitter:description" content="神经网络基础二分分类（logistic回归）计算机保存照片：建立保存三个独立的矩阵，分别对应图片中的红、绿、蓝三个颜色通道（eg：输入图片是64×64像素，则有三个64×64的矩阵）。把这些像素亮度值放进一个特征向量中，就要把这些像素值提出来，放入一个特征向量x，把所有像素值取出来（红、绿、蓝像素强度值都列出来）放入x（1列 64×64×3行）。二分分类：以图片特征向量x作为输入，预测输出的结果标">
<meta name="twitter:image" content="http://yoursite.com/2018/08/05/神经网络（二）/神经网络（二）/1.PNG">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>神经网络（二） | Hexo</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">聪聪&amp;&amp;蝶蝶</a></h1>
        </hgroup>

        
        <p class="header-subtitle">月色与雪色之间，你是第三种绝色。</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/随笔">随笔</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:congy.l@qq.com" title="Email"></a>
                            
                                <a class="fa 新浪微博" href="https://weibo.com/ycong24/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1" title="新浪微博"></a>
                            
                                <a class="fa GitHub" href="https://github.com/yucong9761" title="GitHub"></a>
                            
                                <a class="fa 知乎" href="https://www.zhihu.com/people/sha-gua-bao-da-tui/activities" title="知乎"></a>
                            
                                <a class="fa 简书" href="http://www.jianshu.com/u/014a4b46f9a5" title="简书"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BeautifulSoup/">BeautifulSoup</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scrapy/">Scrapy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/love/">love</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/re（正则表达式）库/">re（正则表达式）库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/元组/">元组</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分数/">分数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/列表/">列表</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/动态类型/">动态类型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/字典/">字典</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/字符串/">字符串</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数字/">数字</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文件/">文件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络综合实验/">网络综合实验</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/软件工程/">软件工程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/随笔/">随笔</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/集合/">集合</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="http://www.baidu.com">百度一下</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://weibo.com">新浪微博</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://www.zhihu.com">知乎</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://music.163.com/">网易云音乐</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">目前仅仅是一枚菜鸟，需要加油喔(*╹▽╹*)</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">聪聪&amp;&amp;蝶蝶</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">聪聪&amp;&amp;蝶蝶</a></h1>
            </hgroup>
            
            <p class="header-subtitle">月色与雪色之间，你是第三种绝色。</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/随笔">随笔</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:congy.l@qq.com" title="Email"></a>
                            
                                <a class="fa 新浪微博" target="_blank" href="https://weibo.com/ycong24/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1" title="新浪微博"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/yucong9761" title="GitHub"></a>
                            
                                <a class="fa 知乎" target="_blank" href="https://www.zhihu.com/people/sha-gua-bao-da-tui/activities" title="知乎"></a>
                            
                                <a class="fa 简书" target="_blank" href="http://www.jianshu.com/u/014a4b46f9a5" title="简书"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="w-神经网络（二）" class="article article-type-w" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/08/05/神经网络（二）/" class="article-date">
      <time datetime="2018-08-05T03:49:12.000Z" itemprop="datePublished">2018-08-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      神经网络（二）
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="神经网络基础"><a href="#神经网络基础" class="headerlink" title="神经网络基础"></a>神经网络基础</h2><h3 id="二分分类（logistic回归）"><a href="#二分分类（logistic回归）" class="headerlink" title="二分分类（logistic回归）"></a>二分分类（logistic回归）</h3><p>计算机保存照片：建立保存三个独立的矩阵，分别对应图片中的红、绿、蓝三个颜色通道（eg：输入图片是64×64像素，则有三个64×64的矩阵）。把这些像素亮度值放进一个特征向量中，就要把这些像素值提出来，放入一个特征向量x，把所有像素值取出来（红、绿、蓝像素强度值都列出来）放入x（1列 64×64×3行）。<br>二分分类：以图片特征向量x作为输入，预测输出的结果标签y（0或1）<br><a id="more"></a></p>
<h4 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h4><p>(x,y)：一个单独的样本   x是nx维的特征向量   标签y值为0或1<br>训练集由m个样本组成，（x1,y1）表示样本一的输入输出……以此类推<br>m：训练样本个数<br><strong>有时会m=m_train(训练样本数)，m_text(测试样本数)</strong><br>用更紧凑的符号表示训练集：定义一个矩阵X由训练集中的x1，x2……组成列，x1放进矩阵第一列，x2放入第二列……行数记为nx，有时将x1,x2……转置，一行行构成X<br>X是一个nx × m的矩阵<br>同理，Y=[y1,y2,……,ym] 1×m的矩阵</p>
<h3 id="logistic回归"><a href="#logistic回归" class="headerlink" title="logistic回归"></a>logistic回归</h3><p>logistic回归：一个学习算法，用在监督学习问题中，输出y标签是0或1，是一个二元分类问题。<br>eg：已知输入特征向量X可能是一张图，希望识别出这是不是猫图。<br>给定x，需要一个算法，给出一个预测值y（准确说y是一个概率，输入x满足条件时y是1）<br>x是一个nx维向量，已知logistic回归的参数是w（也是一个nx维向量），b（一个实数）。已知输入x，参数w和b，输出预测的y。<br>线性回归：y=w^T×x+b<br>由于得到的y是一个概率，则y介于0到1之间，所以不能直接用线性回归。所以，logistic之中y等于sigmoid函数作用于w^T×x+b这个量上<br><strong>sigmoid函数：sigmoid(z)=1/(1+e^(-z)) 当z→∞时，函数→1；当z→-∞，函数→0</strong><br>当实现logistic回归时，要做的是学习参数w和b，所以y变成了比较好的估计，对于y=1的概率比较好的估计。</p>
<h4 id="符号约定"><a href="#符号约定" class="headerlink" title="符号约定"></a>符号约定</h4><p>编程时通常将w和b分开。b对应一个拦截器。<br>定义一个额外特征向量x0，等于1，所以出现x是nx+1维向量。<br>将y定义为sigmoid(θ^T×x)，θ由θ0，θ1……θnx组成的列向量，其中θ0扮演b的角色，θ1到θnx的作用和w一样。<br><strong>注：当实现神经网络时，将b和w看作独立的参数可能更好</strong></p>
<h3 id="logistic回归损失函数"><a href="#logistic回归损失函数" class="headerlink" title="logistic回归损失函数"></a>logistic回归损失函数</h3><p>为了训练logistic回归模型的参数w和b，需要定义一个成本函数。<br>前提：输出y=sigmoid(w^T×x+b)，给出一个m个样本的训练集，在训练集里找到w和b，从而得到输出。对于训练集中得到的预测值y帽，期望接近训练集中的y。</p>
<h4 id="损失函数（误差函数）"><a href="#损失函数（误差函数）" class="headerlink" title="损失函数（误差函数）"></a>损失函数（误差函数）</h4><p>衡量算法运行情况，定义损失函数为y帽和y的差的平方（或平方的二分之一）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L(y帽,y)=1/2(y帽-y)^2</span><br></pre></td></tr></table></figure></p>
<p><strong>注：此时梯度下降算法会失灵</strong><br><strong>更改损失函数，提供一个凸的优化问题</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">L(y帽,y)=-( y * log(y帽) + (1-y) * log(1-y帽) )</span><br><span class="line">此时：1.y为1时，第二项为零，要使损失函数尽可能小，则log(y帽)尽可能大，y帽由sigmoid函数得出，取0到1，则要使y帽尽可能的取到1</span><br><span class="line">2.y为0时，第一项为零，要使损失函数尽可能小，则log(1-y帽)尽可能大，y帽尽可能小，同理，要使y帽尽可能取0</span><br></pre></td></tr></table></figure></p>
<p><strong>注：此损失函数是单个训练样本上，衡量在单个训练样本上的表现。成本函数：衡量在全体训练样本上的表现。</strong></p>
<h3 id="成本函数"><a href="#成本函数" class="headerlink" title="成本函数"></a>成本函数</h3><p>衡量w和b的效果，在全体训练样本上的表现<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">J(w,b)=1/m m∑i=1 L(y帽i,yi)=-1/m m∑i=1 [yi × log(y帽i)+ (1-yi) × log(1-y帽i)]</span><br></pre></td></tr></table></figure></p>
<p><strong>损失函数只用于单个训练样本，成本函数是基于参数的总成本。在训练logistic模型中，要找到合适的w和b，让成本函数J尽可能地小</strong></p>
<h3 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h3><p>训练或学习训练集上的参数w和b<br>找到w和b使其对应的成本函数J值是最小值。成本函数J是一个凸函数。</p>
<ul>
<li>用某初始值初始化w和b（任取值初始化，eg：0）</li>
<li>从初始点开始，朝最陡的下坡方向走一步。（这是一次迭代）</li>
<li>进行反复迭代</li>
<li>即到达全局最优解</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">以J(w)为例（忽略b）</span><br><span class="line">w=w-α dJ(w)/dw</span><br><span class="line">α表示学习率，控制每一次迭代或梯度下降算法中的步长</span><br><span class="line">dJ(w)/dw是导数，对参数w的更新/变量化（一般用dw表示）</span><br><span class="line">通过w=w-α dJ(w,b)/dw来更新w</span><br><span class="line">通过b=b-α dJ(w,b)/db来更新b（实时更新参数w，b）</span><br></pre></td></tr></table></figure>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>一个神经网络的计算按照前向或反向传播过程来实现。首先，计算神经网络的输出，紧接着进行一个反向传输操作，后者我们用来计算出对应的梯度或者导数。<br>计算图eg：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">计算函数J是三个变量a，b，c的函数 J(a,b,c)=3×(a+b×c)</span><br><span class="line">步骤：</span><br><span class="line">1.计算b×c存储在u中</span><br><span class="line">2.计算v=a+c</span><br><span class="line">3.输出J=3×v</span><br></pre></td></tr></table></figure></p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\1.PNG" alt="1.PNG"></p>
<p>上图从左到右计算，输出J。有时有不同的或者一些特殊的输出变量时，J是我们想要优化的（优化需要计算导数）。为计算导数，需从右到左进行计算。</p>
<h3 id="计算图导数计算"><a href="#计算图导数计算" class="headerlink" title="计算图导数计算"></a>计算图导数计算</h3><p>往回传播，计算导数，从右向左，下图为例</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\2.PNG" alt="2.PNG"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">假设计算J对v的导数：直接求 dJ/dv=3 （直接、简单）</span><br><span class="line">计算J对a的导数： dJ/da=dJ/dv × dv/da （两条线、链式法则）</span><br><span class="line">计算J对b、c导数： dJ/db=dJ/du × du/db</span><br></pre></td></tr></table></figure>
<h3 id="logistic回归中的梯度下降法"><a href="#logistic回归中的梯度下降法" class="headerlink" title="logistic回归中的梯度下降法"></a>logistic回归中的梯度下降法</h3><h4 id="单个样本"><a href="#单个样本" class="headerlink" title="单个样本"></a>单个样本</h4><p>导数流程图计算<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">logistic回归的公式：</span><br><span class="line">z=w^T×x+b</span><br><span class="line">y帽=a=sigma(z)</span><br><span class="line">L(a,y)=-(y×log(a)+(1-y)×log(1-a))   （只考虑单个样本）</span><br></pre></td></tr></table></figure></p>
<p>假设只有两个样本x1，x2。计算流程图如下：<br><strong>注：x1，x2指的是样本的两个特征值，所以需要w1，w2两个w参数</strong></p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\3.PNG" alt="3.PNG"></p>
<p>变换参数w和b的值来最小化损失函数。向后传播计算导数</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\4.PNG" alt="4.PNG"></p>
<p>依次向前，链式法则。<br>以上是单个样本实例一次梯度更新步骤。</p>
<h4 id="m个样本"><a href="#m个样本" class="headerlink" title="m个样本"></a>m个样本</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">成本函数：</span><br><span class="line">J(w,b)=1/m m∑i=1 L(ai,yi)</span><br><span class="line"></span><br><span class="line">ai=y帽i=sigma(zi)=sigma(w^T×x+b)</span><br></pre></td></tr></table></figure>
<p>当为一个样本时，如上例。m个样本是一个求和，将单个的成本函数求和成损失函数。同理，求导时相当于每个对参数w进行求导再求和。</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\5.PNG" alt="5.PNG"></p>
<p>对m个样本进行训练（一次训练）</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\6.PNG" alt="6.PNG"></p>
<p>以上存在问题，两个显示for循环。向量化方法</p>
<h3 id="向量化方法"><a href="#向量化方法" class="headerlink" title="向量化方法"></a>向量化方法</h3><p>向量化：<br>logistic回归：z=w^T×x+b（w和x都是nx维列向量）<br>非向量化方法：<br>for循环w和x里的每个元素并对其两两相乘然后累加得到结果。<br>向量化方法：<br>直接计算w，x<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z=np.dot(w,x)+b</span><br></pre></td></tr></table></figure></p>
<p>CPU、GPU都有并行化指令（SIMD指令），单指令流多数据流（充分利用并行化去更快计算）。<br>只要有其他可能，就不要使用显示for循环。</p>
<h4 id="向量化例子"><a href="#向量化例子" class="headerlink" title="向量化例子"></a>向量化例子</h4><ul>
<li><p>向量相乘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">已知向量u，v</span><br><span class="line">import numpy as np</span><br><span class="line">z=np.dot(u,v)</span><br></pre></td></tr></table></figure>
</li>
<li><p>指数运算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">内存有一个向量v[v1,v2,……,vn]，指数运算作用到v中的每个元素</span><br><span class="line">import numpy as np</span><br><span class="line">u=np.exp(v)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>numpy库有很多内置函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.log(v) 逐个元素取log</span><br><span class="line">np.Abs(v) 计算绝对值</span><br><span class="line">np.maximum(v,0) 求出v中所有元素和0之间相比的最大值</span><br><span class="line">v××2 v中每个元素的平方</span><br><span class="line">1/v 每个元素求倒数</span><br></pre></td></tr></table></figure></p>
<p><strong>当需要调用for循环时，首先看看能否调用numpy的内置函数</strong><br>使用向量化进行logistic回归梯度下降。</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\7.PNG" alt="7.PNG"></p>
<h3 id="向量化logistic回归"><a href="#向量化logistic回归" class="headerlink" title="向量化logistic回归"></a>向量化logistic回归</h3><p>向量化实现在logistic回归上，同时处理整个训练集来实现梯度下降法的一步迭代，针对整个训练集，不需要使用任何显示for循环。<br>logistic回归的正向传播步骤（m个样本以此类推）：</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\8.PNG" alt="8.PNG"></p>
<p><strong>向量化：</strong><br>X矩阵（nx×m）作为训练输入，首先构造一个1×m的矩阵Z，用来存储z1，z2，z3……，一个1×m矩阵A存储a1,a2,……<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[z1,z2,z3,……,zm]=w^T×X+[b,b,b,……,b]</span><br><span class="line">numpy指令即Z=np.dot(w^T,X)+b</span><br><span class="line">A=sigma(Z)</span><br><span class="line">注：b为一个实数，python会通过广播，自动将z1,z2……都加上b</span><br></pre></td></tr></table></figure></p>
<h3 id="向量化logistic回归的梯度输出"><a href="#向量化logistic回归的梯度输出" class="headerlink" title="向量化logistic回归的梯度输出"></a>向量化logistic回归的梯度输出</h3><p>向量化计量m个训练数据的梯度<br>目前只去掉一个for循环，还存在一个遍历整个训练集样本的for循环。<br>db=1/m np.sum(dz)<br>dw=1/m Xdz^T</p>
<p>向量化计算：</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\9.PNG" alt="9.PNG"></p>
<p>完成了正向和反向传播，对所有训练样本进行预测和求导，没有使用for循环，然后使用梯度下降更新参数。以上，就是logistic回归的梯度下降一次迭代。但如果希望多次迭代进行梯度下降，仍需要for循环</p>
<h3 id="python中的广播"><a href="#python中的广播" class="headerlink" title="python中的广播"></a>python中的广播</h3><p>例子：</p>
<p><img src="/2018/08/05/神经网络（二）/神经网络（二）\10.PNG" alt="10.PNG"></p>
<p><strong>python/numpy向量注意：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a=np.random.randn(5)  秩为1的数组</span><br><span class="line">a=a.reshape(5,1) 把a转换成5×1的数组</span><br><span class="line">a=np.random.randn((5,1))</span><br><span class="line">a=np.random.randn((1,5))</span><br><span class="line">assert(a.shape=(5,1))  确保a是一个向量</span><br></pre></td></tr></table></figure></p>
<p><strong>不用秩为1的数组，简化代码，始终使用n×1矩阵（基本是列向量）或者1×n矩阵（基本是行向量），插入assert声明，检查矩阵和数组的维度，调用reshape来确保矩阵或者向量是需要的维度。</strong></p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2018/08/05/神经网络（二）/">神经网络（二）</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">聪聪&amp;&amp;蝶蝶</a></p>
        <p><span>发布时间:</span>2018-08-05, 11:49:12</p>
        <p><span>最后更新:</span>2018-08-09, 11:17:15</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2018/08/05/神经网络（二）/" title="神经网络（二）">http://yoursite.com/2018/08/05/神经网络（二）/</a>
            <span class="copy-path" data-clipboard-text="原文: http://yoursite.com/2018/08/05/神经网络（二）/　　作者: 聪聪&amp;&amp;蝶蝶" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2018/08/05/神经网络（一）/">
                    神经网络（一）
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络基础"><span class="toc-number">1.</span> <span class="toc-text">神经网络基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#二分分类（logistic回归）"><span class="toc-number">1.1.</span> <span class="toc-text">二分分类（logistic回归）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#符号"><span class="toc-number">1.1.1.</span> <span class="toc-text">符号</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#logistic回归"><span class="toc-number">1.2.</span> <span class="toc-text">logistic回归</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#符号约定"><span class="toc-number">1.2.1.</span> <span class="toc-text">符号约定</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#logistic回归损失函数"><span class="toc-number">1.3.</span> <span class="toc-text">logistic回归损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#损失函数（误差函数）"><span class="toc-number">1.3.1.</span> <span class="toc-text">损失函数（误差函数）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#成本函数"><span class="toc-number">1.4.</span> <span class="toc-text">成本函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降算法"><span class="toc-number">1.5.</span> <span class="toc-text">梯度下降算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算图"><span class="toc-number">1.6.</span> <span class="toc-text">计算图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算图导数计算"><span class="toc-number">1.7.</span> <span class="toc-text">计算图导数计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#logistic回归中的梯度下降法"><span class="toc-number">1.8.</span> <span class="toc-text">logistic回归中的梯度下降法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#单个样本"><span class="toc-number">1.8.1.</span> <span class="toc-text">单个样本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#m个样本"><span class="toc-number">1.8.2.</span> <span class="toc-text">m个样本</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#向量化方法"><span class="toc-number">1.9.</span> <span class="toc-text">向量化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#向量化例子"><span class="toc-number">1.9.1.</span> <span class="toc-text">向量化例子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#向量化logistic回归"><span class="toc-number">1.10.</span> <span class="toc-text">向量化logistic回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#向量化logistic回归的梯度输出"><span class="toc-number">1.11.</span> <span class="toc-text">向量化logistic回归的梯度输出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#python中的广播"><span class="toc-number">1.12.</span> <span class="toc-text">python中的广播</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-4 i,
        .toc-level-4 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"神经网络（二）　| Hexo　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/" title="回到主页"><i class="fa fa-home"></i></a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2018/08/05/神经网络（一）/" title="下一篇: 神经网络（一）">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/05/神经网络（二）/">神经网络（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/05/神经网络（一）/">神经网络（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/01/吴恩达机器学习/">吴恩达机器学习（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/19/python正则表达式/">python正则表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/关于淘宝商品的数据分析/">关于淘宝商品的数据分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/腻歪时间轴/">腻歪时间轴</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/11/聪聪and蝶蝶/">聪聪and蝶蝶</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/18/JavaScript-一/">JavaScript(一)</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/03/网络综合实验命令/">网络综合实验命令</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/17/python网络爬虫（九）/">python网络爬虫（九）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/15/交换机端口配置与生成树协议配置/">交换机端口配置与生成树协议配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/14/登入交换机和COMWARE基本使用/">登入交换机和COMWARE基本使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/12/vim（一）/">vim（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/10/python网络爬虫（八）/">python网络爬虫（八）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/07/python网络爬虫（七）/">python网络爬虫（七）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/06/python网络爬虫（六）/">python网络爬虫（六）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/06/python网络爬虫（五）/">python网络爬虫（五）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/05/python基本知识（七）/">python基本知识（七）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/05/python基本知识（六）/">python基本知识（六）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/04/python基本知识（五）/">python基本知识（五）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/03/python基本知识（四）/">python基本知识（四）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/03/python基本知识（三）/">python基本知识（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/01/python基本知识（二）/">python基本知识（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/30/python基本知识（一）/">python基本知识（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/29/python网络爬虫（四）/">python网络爬虫（四）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/29/python网络爬虫（三）/">python网络爬虫（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/29/软件工程复习（一）/">软件工程复习（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/28/python网络爬虫（二）/">python网络爬虫（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/27/python网络爬虫（一）/">python网络爬虫（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/26/my-first-blog/">my first blog</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/23/hello-world/">Hello World</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017-2018 聪聪&amp;&amp;蝶蝶
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 6;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
             title: "a.article-title, .article-more-link a", 
             post: ".article-entry a[href], .copyright a[href]", 
             tags: ".article-tag a", 
             categories: ".article-category a, a.tag-list-link", 
             articleNav: "#article-nav a, #post-nav-button a", 
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
             menu: ".header-menu a", 
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>